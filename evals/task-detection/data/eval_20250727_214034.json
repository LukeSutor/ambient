{
  "timestamp": "2025-07-27T21:40:34.880245100+00:00",
  "prev_prev_screen_state": {
    "data": [
      {
        "process_id": 29176,
        "process_name": "brave.exe",
        "application_name": "Brave Browser",
        "text_content": [
          "Feature Request: Apple just release Fast-VLM, a very promising set of multimodal language models ¬∑ Issue #13512 ¬∑ ggml-org/llama.cpp",
          "Type",
          "to search",
          "Issues",
          "Pull requests",
          "Projects",
          "Security",
          "Feature Request: Apple just release Fast-VLM, a very promising set of multimodal language models",
          "#13512",
          "Closed",
          "opened",
          "on May 13",
          "Contributor",
          "I am running the latest code. Mention the version if possible as well.",
          "I carefully followed the",
          "I searched using keywords relevant to my issue to make sure that I am creating a new issue that is not already open (or closed).",
          "I reviewed the",
          ", and have a new and useful enhancement to share.",
          "Apple just release Fast-VLM, a very promising set of multimodal language models:",
          "Please support these models and their quants in llama.cpp",
          "These models pack a lot of bang for their rather modest size.",
          "No response",
          "üëç",
          "üëÄ",
          "added",
          "enhancement",
          "changed the title",
          "Feature Request:",
          "on Jun 12",
          "bot",
          "on Jun 26",
          "This issue was closed because it has been inactive for 14 days since being marked as stale.",
          "closed this",
          "as",
          "No one assigned",
          "No type",
          "No projects",
          "No milestone",
          "None yet",
          "No branches or pull requests",
          "You're not receiving notifications from this thread.",
          "Address and search bar"
        ]
      },
      {
        "process_id": 20268,
        "process_name": "notepad.exe",
        "application_name": "Notepad",
        "text_content": [
          "Text Editor",
          "Ln 4, Col 1",
          "100%",
          "Windows (CRLF)",
          "UTF-8"
        ]
      }
    ],
    "active_url": "github.com/ggml-org/llama.cpp/issues/13512",
    "timestamp": "2025-07-27T21:39:17.570951300+00:00",
    "summary": "The user is engaging in a feature request on GitHub, specifically for Apple's Fast-VLM multimodal language models in the llama.cpp project."
  },
  "prev_screen_state": {
    "data": [
      {
        "process_id": 20268,
        "process_name": "notepad.exe",
        "application_name": "Notepad",
        "text_content": [
          "Text Editor",
          "Ln 4, Col 1",
          "100%",
          "Windows (CRLF)",
          "UTF-8"
        ]
      },
      {
        "process_id": 29176,
        "process_name": "brave.exe",
        "application_name": "Brave Browser",
        "text_content": [
          "[2506.21734] Hierarchical Reasoning Model",
          "We gratefully acknowledge support from",
          "the Simons Foundation,",
          ", and all contributors.",
          "arXiv:2506.21734",
          "Search term or terms",
          "[Submitted on 26 Jun 2025 (",
          "), last revised 22 Jul 2025 (this version, v2)]",
          "Reasoning, the process of devising and executing complex goal-oriented action sequences, remains a critical challenge in AI. Current large language models (LLMs) primarily employ Chain-of-Thought (CoT) techniques, which suffer from brittle task decomposition, extensive data requirements, and high latency. Inspired by the hierarchical and multi-timescale processing in the human brain, we propose the Hierarchical Reasoning Model (HRM), a novel recurrent architecture that attains significant computational depth while maintaining both training stability and efficiency. HRM executes sequential reasoning tasks in a single forward pass without explicit supervision of the intermediate process, through two interdependent recurrent modules: a high-level module responsible for slow, abstract planning, and a low-level module handling rapid, detailed computations. With only 27 million parameters, HRM achieves exceptional performance on complex reasoning tasks using only 1000 training samples. The model operates without pre-training or CoT data, yet achieves nearly perfect performance on challenging tasks including complex Sudoku puzzles and optimal path finding in large mazes. Furthermore, HRM outperforms much larger models with significantly longer context windows on the Abstraction and Reasoning Corpus (ARC), a key benchmark for measuring artificial general intelligence capabilities. These results underscore HRM's potential as a transformative advancement toward universal computation and general-purpose reasoning systems.",
          "Artificial Intelligence (cs.AI)",
          "; Machine Learning (cs.LG)",
          "[cs.AI]",
          "(or",
          "for this version)",
          "From: Yuhao Sun [",
          "Thu, 26 Jun 2025 19:39:54 UTC (1,542 KB)",
          "[v2]",
          "Tue, 22 Jul 2025 06:45:57 UTC (1,525 KB)",
          "Current browse context:",
          "cs.AI",
          "Change to browse by:",
          "Export BibTeX Citation",
          "Bibliographic Tools",
          "Bibliographic Explorer Toggle",
          "Bibliographic Explorer",
          "Connected Papers Toggle",
          "Connected Papers",
          "Litmaps Toggle",
          "Litmaps",
          "scite.ai Toggle",
          "scite Smart Citations",
          "Code, Data, Media",
          "Demos",
          "Related Papers",
          "About arXivLabs",
          "Get status notifications via",
          "or",
          "Address and search bar"
        ]
      }
    ],
    "active_url": "arxiv.org/abs/2506.21734",
    "timestamp": "2025-07-27T21:40:09.638627200+00:00",
    "summary": "The user is reviewing a research paper related to the Hierarchical Reasoning Model in the context of Artificial Intelligence, with the arXiv:2506.21734 document being browsed."
  },
  "screen_diff_markdown": "# Screen Text by Application\n\n## Brave Browser (PID: 29176)\n\n[2506.21734] Hierarchical Reasoning Model\nWe gratefully acknowledge support from\nthe Simons Foundation,\n, and all contributors.\narXiv:2506.21734\nSearch term or terms\n[Submitted on 26 Jun 2025 (\n), last revised 22 Jul 2025 (this version, v2)]\nReasoning, the process of devising and executing complex goal-oriented action sequences, remains a critical challenge in AI. Current large language models (LLMs) primarily employ Chain-of-Thought (CoT) techniques, which suffer from brittle task decomposition, extensive data requirements, and high latency. Inspired by the hierarchical and multi-timescale processing in the human brain, we propose the Hierarchical Reasoning Model (HRM), a novel recurrent architecture that attains significant computational depth while maintaining both training stability and efficiency. HRM executes sequential reasoning tasks in a single forward pass without explicit supervision of the intermediate process, through two interdependent recurrent modules: a high-level module responsible for slow, abstract planning, and a low-level module handling rapid, detailed computations. With only 27 million parameters, HRM achieves exceptional performance on complex reasoning tasks using only 1000 training samples. The model operates without pre-training or CoT data, yet achieves nearly perfect performance on challenging tasks including complex Sudoku puzzles and optimal path finding in large mazes. Furthermore, HRM outperforms much larger models with significantly longer context windows on the Abstraction and Reasoning Corpus (ARC), a key benchmark for measuring artificial general intelligence capabilities. These results underscore HRM's potential as a transformative advancement toward universal computation and general-purpose reasoning systems.\nArtificial Intelligence (cs.AI)\n; Machine Learning (cs.LG)\n[cs.AI]\n(or\nfor this version)\nFrom: Yuhao Sun [\nThu, 26 Jun 2025 19:39:54 UTC (1,542 KB)\n[v2]\nTue, 22 Jul 2025 06:45:57 UTC (1,525 KB)\nCurrent browse context:\ncs.AI\nChange to browse by:\nExport BibTeX Citation\nBibliographic Tools\nBibliographic Explorer Toggle\nBibliographic Explorer\nConnected Papers Toggle\nConnected Papers\nLitmaps Toggle\nLitmaps\nscite.ai Toggle\nscite Smart Citations\nCode, Data, Media\nDemos\nRelated Papers\nAbout arXivLabs\nGet status notifications via\nor\n\n",
  "prev_prev_summary": "The user is engaging in a feature request on GitHub, specifically for Apple's Fast-VLM multimodal language models in the llama.cpp project.",
  "active_tasks": [
    {
      "task": {
        "id": 1,
        "name": "Check for internships",
        "description": "Browse job postings to check for summer internships",
        "category": null,
        "priority": 1,
        "frequency": "daily",
        "last_completed_at": null,
        "first_scheduled_at": "2025-07-27T21:40:34.879971700Z",
        "created_at": "2025-07-27T21:40:34.879978Z",
        "updated_at": "2025-07-27T21:40:34.879982200Z",
        "status": "pending"
      },
      "steps": [
        {
          "id": 1,
          "task_id": 1,
          "step_number": 1,
          "title": "Check summer 2026",
          "description": "Navigate to https://github.com/vanshb03/Summer2026-Internships and check the readme for new postings",
          "status": "pending",
          "completed_at": null
        },
        {
          "id": 2,
          "task_id": 1,
          "step_number": 2,
          "title": "Check spring 2026",
          "description": "Navigate to https://github.com/vanshb03/Summer2026-Internships/blob/dev/OFFSEASON_README.md and check for new internships",
          "status": "pending",
          "completed_at": null
        }
      ],
      "progress_percentage": 0.0
    }
  ],
  "formatted_tasks": "Task Check for internships,  Description: Browse job postings to check for summer internships, Steps: [\n\tStep: Check summer 2026, ID: 1, Description: Navigate to https://github.com/vanshb03/Summer2026-Internships and check the readme for new postings, Status: pending\n\tStep: Check spring 2026, ID: 2, Description: Navigate to https://github.com/vanshb03/Summer2026-Internships/blob/dev/OFFSEASON_README.md and check for new internships, Status: pending\n]",
  "ground_truth_completed_step_ids": []
}